{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# from moviepy.editor import *\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import yt_dlp\n",
    "# from yt_dlp import YoutubeDL\n",
    "# import moviepy.editor as mp\n",
    "\n",
    "# # Set yt-dlp as the backend for pafy\n",
    "# os.environ[\"PYPYDL_PYPI_PACKAGE\"] = \"yt-dlp\"\n",
    "\n",
    "# # Create a YoutubeDL instance and set it to the pafy backend\n",
    "# def new_pafy_backend():\n",
    "#     yt_dlp_options = {'format': 'bestaudio/best'}\n",
    "#     return YoutubeDL(yt_dlp_options)\n",
    "\n",
    "# pafy.backend_shared.backend = new_pafy_backend()\n",
    "\n",
    "# import pafy\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Create a pafy object\n",
    "#         video = pafy.new(youtube_url)\n",
    "\n",
    "#         # Select the best audio stream\n",
    "#         best_audio = video.getbestaudio()\n",
    "\n",
    "#         # Temporary filename\n",
    "#         temp_filename = 'temp_audio.' + best_audio.extension\n",
    "\n",
    "#         # Download the audio stream to a temporary file\n",
    "#         best_audio.download(filepath=temp_filename)\n",
    "\n",
    "#         # Convert the downloaded file to MP3\n",
    "#         clip = mp.AudioFileClip(temp_filename)\n",
    "#         clip.write_audiofile(output_path)\n",
    "\n",
    "#         # Close the clip to free resources\n",
    "#         clip.close()\n",
    "\n",
    "#         # Remove the temporary file\n",
    "#         os.remove(temp_filename)\n",
    "\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'output/testing.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_youtube_audio(youtube_url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytube\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt = pytube.YouTube(\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# import ffmpeg\n",
    "\n",
    "# text = 'https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan'\n",
    "\n",
    "# yt = YouTube(text)\n",
    "\n",
    "# # https://github.com/pytube/pytube/issues/301\n",
    "# stream_url = yt.streams.all()[0].url  # Get the URL of the video stream\n",
    "\n",
    "# # Probe the audio streams (use it in case you need information like sample rate):\n",
    "# #probe = ffmpeg.probe(stream_url)\n",
    "# #audio_streams = next((stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
    "# #sample_rate = audio_streams['sample_rate']\n",
    "\n",
    "# # Read audio into memory buffer.\n",
    "# # Get the audio using stdout pipe of ffmpeg sub-process.\n",
    "# # The audio is transcoded to PCM codec in WAC container.\n",
    "# audio, err = (\n",
    "#     ffmpeg\n",
    "#     .input(stream_url)\n",
    "#     .output(\"pipe:\", format='wav', acodec='pcm_s16le')  # Select WAV output format, and pcm_s16le auidio codec. My add ar=sample_rate\n",
    "#     .run(capture_stdout=True)\n",
    "# )\n",
    "\n",
    "# # Write the audio buffer to file for testing\n",
    "# with open('audio.wav', 'wb') as f:\n",
    "#     f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s'\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Path to ffmpeg binary\n",
    "#         ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "# ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "# with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#     ydl.download([\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Get the ffmpeg binary path from imageio_ffmpeg\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path,\n",
    "#             'verbose': True  # Enable verbose logging for debugging\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Working below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking  e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win64-v4.2.2.exe\n",
      "Download and conversion complete. File saved as audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "def download_youtube_audio(youtube_url, output_path):\n",
    "    try:\n",
    "        # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "        print(\"checking \", ffmpeg_path)\n",
    "        # Construct the yt-dlp command\n",
    "        cmd = [\n",
    "            'yt-dlp',\n",
    "            '-x',  # Extract audio only\n",
    "            '--audio-format', 'mp3',\n",
    "            '--ffmpeg-location', ffmpeg_path,\n",
    "            '-o', output_path,  # Output file template\n",
    "            youtube_url  # YouTube video URL\n",
    "        ]\n",
    "\n",
    "        # Run the command using subprocess\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            print(\"checking resturn.returncode \", result.returncode)\n",
    "            print(f\"Error occurred: {result.stderr}\")\n",
    "        else:\n",
    "            print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error checking \")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=x7X9w_GIm1s&ab_channel=Fireship\"\n",
    "\n",
    "# Output path for the converted MP3 file\n",
    "output_path = 'extracted_audio/audio.mp3'\n",
    "\n",
    "download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import yt_dlp\n",
    "\n",
    "# def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "#     try:\n",
    "#         # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # Create output directory if it doesn't exist\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "\n",
    "#         # Options to retrieve video info from playlist\n",
    "#         ydl_opts = {\n",
    "#             'quiet': True,\n",
    "#             'extract_flat': True,\n",
    "#             'force_generic_extractor': True,\n",
    "#         }\n",
    "\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             playlist_info = ydl.extract_info(playlist_url, download=False)\n",
    "\n",
    "#         # Check if the URL is a playlist and has entries\n",
    "#         if 'entries' not in playlist_info:\n",
    "#             print(\"The provided URL is not a playlist or has no entries.\")\n",
    "#             return\n",
    "\n",
    "#         # Iterate through each video in the playlist\n",
    "#         for index, entry in enumerate(playlist_info['entries'], start=1):\n",
    "#             video_url = entry['url']\n",
    "#             output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "#             # Construct the yt-dlp command\n",
    "#             cmd = [\n",
    "#                 'yt-dlp',\n",
    "#                 '-x',  # Extract audio only\n",
    "#                 '--audio-format', 'mp3',\n",
    "#                 '--ffmpeg-location', ffmpeg_path,\n",
    "#                 '-o', output_path,  # Output file template\n",
    "#                 video_url  # YouTube video URL\n",
    "#             ]\n",
    "\n",
    "#             # Run the command using subprocess\n",
    "#             result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#             # Check for errors\n",
    "#             if result.returncode != 0:\n",
    "#                 print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "#             else:\n",
    "#                 print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube playlist URL\n",
    "# playlist_url = \"https://youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR&si=bJn2d1cvuOlb10qC\"\n",
    "\n",
    "# # Output directory for the converted MP3 files\n",
    "# output_dir = 'extracted_audio'\n",
    "\n",
    "# download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For playlist download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'list'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AA\\AppData\\Local\\Temp\\ipykernel_15156\\4028681533.py\", line 17, in download_youtube_audio_playlist\n",
      "    video_urls = [video.watch_url for video in playlist.videos]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 296, in videos_generator\n",
      "    for url in self.video_urls:\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 281, in url_generator\n",
      "    for page in self._paginate():\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 118, in _paginate\n",
      "    json.dumps(extract.initial_data(self.html))\n",
      "                                    ^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 58, in html\n",
      "    self._html = request.get(self.playlist_url)\n",
      "                             ^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 48, in playlist_url\n",
      "    return f\"https://www.youtube.com/playlist?list={self.playlist_id}\"\n",
      "                                                    ^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 39, in playlist_id\n",
      "    self._playlist_id = extract.playlist_id(self._input_url)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\extract.py\", line 151, in playlist_id\n",
      "    return parse_qs(parsed.query)['list'][0]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "KeyError: 'list'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "from pytube import Playlist\n",
    "\n",
    "def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "    try:\n",
    "        # Path to ffmpeg executable\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Get video URLs from the playlist using pytube\n",
    "        playlist = Playlist(playlist_url)\n",
    "        video_urls = [video.watch_url for video in playlist.videos]\n",
    "\n",
    "        # Iterate through each video in the playlist\n",
    "        for index, video_url in enumerate(video_urls, start=1):\n",
    "            output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "            # Construct the yt-dlp command\n",
    "            cmd = [\n",
    "                'yt-dlp',\n",
    "                '-x',  # Extract audio only\n",
    "                '--audio-format', 'mp3',\n",
    "                '--ffmpeg-location', ffmpeg_path,\n",
    "                '-o', output_path,  # Output file template\n",
    "                video_url  # YouTube video URL\n",
    "            ]\n",
    "\n",
    "            # Run the command using subprocess\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            # Check for errors\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "            else:\n",
    "                print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube playlist URL\n",
    "playlist_url = \"https://www.youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR\"\n",
    "\n",
    "# Output directory for the converted MP3 files\n",
    "output_dir = 'extracted_audio'\n",
    "\n",
    "download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Transcript Vosk is working very poor trying to shift to deepspeesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import json\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model):\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     print(\"checking wf \", wf)\n",
    "#     rec = KaldiRecognizer(model, wf.getframerate())\n",
    "#     rec.SetWords(True)\n",
    "#     results = []\n",
    "#     while True:\n",
    "#         data = wf.readframes(4000)\n",
    "#         if len(data) == 0:\n",
    "#             break\n",
    "#         if rec.AcceptWaveform(data):\n",
    "#             results.append(json.loads(rec.Result()))\n",
    "#         else:\n",
    "#             results.append(json.loads(rec.PartialResult()))\n",
    "#     results.append(json.loads(rec.FinalResult()))\n",
    "#     text = ' '.join([res['text'] for res in results if 'text' in res])\n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     # Verify model path\n",
    "#     if not os.path.exists(model_path):\n",
    "#         raise Exception(f\"Model path {model_path} does not exist. Please check the path and try again.\")\n",
    "    \n",
    "#     print(f\"Loading Vosk model from {model_path}...\")\n",
    "\n",
    "#     try:\n",
    "#         print(\"model creation checking \")\n",
    "#         # Load the Vosk model\n",
    "#         model = Model(model_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to create a model from the path {model_path}. Error: {e}\")\n",
    "#         return\n",
    "\n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/vosk-model-en-us-0.42-gigaspeech'  # Replace with your Vosk model path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DeepSpeech by Mozila taking too much time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepSpeech model from audio_model/deepspeech-0.9.3-models.pbmm...\n",
      "Loading DeepSpeech scorer from audio_model/deepspeech-0.9.3-models.scorer...\n",
      "checking audio load  <pydub.audio_segment.AudioSegment object at 0x000001C2AD27A130>\n",
      "Converted extracted_audio\\audio.mp3 to transcription_results\\audio1.wav\n",
      "Starting transcription for transcription_results\\audio1.wav...\n",
      "Enabling scorer...\n",
      "Running model.stt...\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import numpy as np\n",
    "# import deepspeech\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model, scorer):\n",
    "#     print(f\"Starting transcription for {wav_file_path}...\")\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     fs = wf.getframerate()\n",
    "#     audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "    \n",
    "#     print(\"Enabling scorer...\")\n",
    "#     model.enableExternalScorer(scorer)\n",
    "#     print(\"Running model.stt...\")\n",
    "#     text = model.stt(audio)\n",
    "    \n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path, scorer_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "    \n",
    "#     print(f\"Loading DeepSpeech model from {model_path}...\")\n",
    "#     model = deepspeech.Model(model_path)\n",
    "#     print(f\"Loading DeepSpeech scorer from {scorer_path}...\")\n",
    "#     model.enableExternalScorer(scorer_path)\n",
    "    \n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model, scorer_path)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/deepspeech-0.9.3-models.pbmm'  # Replace with your DeepSpeech model path\n",
    "# scorer_path = 'audio_model/deepspeech-0.9.3-models.scorer'  # Replace with your DeepSpeech scorer path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path, scorer_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using amazon Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket audiootextai already exists.\n",
      "File extracted_audio/audio1.mp3 uploaded to S3 bucket audiootextai with key audio1.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcript downloaded to transcription_results/transcript1.json\n",
      "Transcript saved to transcription_results/transcript1.txt\n",
      "File extracted_audio/audio2.mp3 uploaded to S3 bucket audiootextai with key audio2.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcript downloaded to transcription_results/transcript2.json\n",
      "Transcript saved to transcription_results/transcript2.txt\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize Boto3 clients\n",
    "# Use a specific profile\n",
    "session = boto3.Session(profile_name='default')\n",
    "s3_client = session.client('s3')\n",
    "transcribe_client = session.client('transcribe')\n",
    "\n",
    "# Constants\n",
    "bucket_name = 'audiootextai'  # Replace with your S3 bucket name\n",
    "region = 'us-east-1'  # Replace with your AWS region\n",
    "\n",
    "def create_s3_bucket(bucket_name, region):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket {bucket_name} created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket {bucket_name}: {e}\")\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, s3_key):\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"File {file_path} uploaded to S3 bucket {bucket_name} with key {s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "def start_transcription_job(job_name, s3_uri, language_code='en-US'):\n",
    "    try:\n",
    "        response = transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': s3_uri},\n",
    "            MediaFormat='mp3',\n",
    "            LanguageCode=language_code,\n",
    "            OutputBucketName=bucket_name\n",
    "        )\n",
    "        print(f\"Started transcription job with name: {job_name}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting transcription job: {e}\")\n",
    "\n",
    "def get_transcription_result(job_name):\n",
    "    while True:\n",
    "        response = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if status in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        print(f\"Transcription job {job_name} status: {status}\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    if status == 'COMPLETED':\n",
    "        transcript_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "        print(f\"Transcription completed. Transcript URI: {transcript_uri}\")\n",
    "        return transcript_uri\n",
    "    else:\n",
    "        print(f\"Transcription job {job_name} failed.\")\n",
    "        return None\n",
    "\n",
    "def download_transcript(transcript_uri, output_path):\n",
    "    try:\n",
    "        response = requests.get(transcript_uri)\n",
    "        response.raise_for_status()\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Transcript downloaded to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading transcript: {e}\")\n",
    "\n",
    "def extract_transcript_from_file(json_file_path, output_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            # Extracting the transcript text\n",
    "            transcript_text = data['results']['transcripts'][0]['transcript']\n",
    "            \n",
    "            # Save the clean transcript to a text file\n",
    "            with open(output_file_path, 'w') as text_file:\n",
    "                text_file.write(transcript_text)\n",
    "            print(f\"Transcript saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {json_file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    file_paths = ['extracted_audio/audio1.mp3', 'extracted_audio/audio2.mp3']  # Replace with your list of MP3 file paths\n",
    "\n",
    "    # Check if the bucket exists and create it if not\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except:\n",
    "        print(f\"Bucket {bucket_name} does not exist. Creating bucket...\")\n",
    "        create_s3_bucket(bucket_name, region)\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('transcription_results', exist_ok=True)\n",
    "\n",
    "    for i, file_path in enumerate(file_paths, start=1):\n",
    "        s3_key = f'audio{i}.mp3'\n",
    "        job_name = f'transcription-job-{i}'\n",
    "        transcript_output_path = f'transcription_results/transcript{i}.json'\n",
    "        clean_text_output_path = f'transcription_results/transcript{i}.txt'\n",
    "\n",
    "        # Upload the file to S3\n",
    "        upload_file_to_s3(file_path, bucket_name, s3_key)\n",
    "\n",
    "        # Start transcription job\n",
    "        s3_uri = f's3://{bucket_name}/{s3_key}'\n",
    "        start_transcription_job(job_name, s3_uri)\n",
    "\n",
    "        # Get transcription result\n",
    "        transcript_uri = get_transcription_result(job_name)\n",
    "        if transcript_uri:\n",
    "            print(f\"Transcription result available at: {transcript_uri}\")\n",
    "            # Download the transcription result\n",
    "            download_transcript(transcript_uri, transcript_output_path)\n",
    "            # Extract clean text and save to file\n",
    "            extract_transcript_from_file(transcript_output_path, clean_text_output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma db setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerEmbeddings\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      7\u001b[0m load_dotenv()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_huggingface'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import os\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = './embedding_model'\n",
    "\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "\n",
    "huggingfacehub_api_token=os.getenv(\"huggingfacehub_api_token\")\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "# create the open-source embedding function\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "\n",
    "persist_directory = './chroma_db'\n",
    "\n",
    "\n",
    "transcription_dir = \"./transcription_results\"\n",
    "for file_name in os.listdir(transcription_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(transcription_dir, file_name)\n",
    "            loader = TextLoader(file_path)\n",
    "            documents = loader.load()\n",
    "            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "            docs = text_splitter.split_documents(documents)\n",
    "            hf_embeddings.embed_documents(docs)\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=docs, embedding=hf_embedding, persist_directory=persist_directory)\n",
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "query = \"Kamala Harris performs about the same, maybe a little better nationally up against Donald Trump.\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3 setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at E:\\HuggingFaceCache\\hub\\models--intfloat--e5-large-v2\\snapshots\\b322e09026e4ea05f42beadf4d661fb4e101d311\\vocab.txt\n",
      "loading file tokenizer.json from cache at E:\\HuggingFaceCache\\hub\\models--intfloat--e5-large-v2\\snapshots\\b322e09026e4ea05f42beadf4d661fb4e101d311\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at E:\\HuggingFaceCache\\hub\\models--intfloat--e5-large-v2\\snapshots\\b322e09026e4ea05f42beadf4d661fb4e101d311\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at E:\\HuggingFaceCache\\hub\\models--intfloat--e5-large-v2\\snapshots\\b322e09026e4ea05f42beadf4d661fb4e101d311\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at E:\\HuggingFaceCache\\hub\\models--intfloat--e5-large-v2\\snapshots\\b322e09026e4ea05f42beadf4d661fb4e101d311\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"intfloat/e5-large-v2\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.42.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintfloat/e5-large-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_text\u001b[39m(text):\n\u001b[0;32m     24\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\modeling_utils.py:3428\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3413\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   3414\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[0;32m   3416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[0;32m   3427\u001b[0m     }\n\u001b[1;32m-> 3428\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs)\n\u001b[0;32m   3430\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   3431\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   3432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   3433\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    551\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llama_model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llama_model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"auto\",\n",
    ")\n",
    "\n",
    "def generate_response(context, question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "        {\"role\": \"user\", \"content\": context + \"\\n\" + question},\n",
    "    ]\n",
    "    prompt = llama_pipeline.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    terminators = [\n",
    "        llama_pipeline.tokenizer.eos_token_id,\n",
    "        llama_pipeline.tokenizer.convert_tokens_to_ids(\"\")\n",
    "    ]\n",
    "    outputs = llama_pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "def answer_question(question):\n",
    "    docs = db.similarity_search(question)\n",
    "    context = \" \".join([doc.page_content for doc in docs])\n",
    "    response = generate_response(context, question)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the main topic of the first lecture?\"\n",
    "answer = answer_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
