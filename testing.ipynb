{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# from moviepy.editor import *\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import yt_dlp\n",
    "# from yt_dlp import YoutubeDL\n",
    "# import moviepy.editor as mp\n",
    "\n",
    "# # Set yt-dlp as the backend for pafy\n",
    "# os.environ[\"PYPYDL_PYPI_PACKAGE\"] = \"yt-dlp\"\n",
    "\n",
    "# # Create a YoutubeDL instance and set it to the pafy backend\n",
    "# def new_pafy_backend():\n",
    "#     yt_dlp_options = {'format': 'bestaudio/best'}\n",
    "#     return YoutubeDL(yt_dlp_options)\n",
    "\n",
    "# pafy.backend_shared.backend = new_pafy_backend()\n",
    "\n",
    "# import pafy\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Create a pafy object\n",
    "#         video = pafy.new(youtube_url)\n",
    "\n",
    "#         # Select the best audio stream\n",
    "#         best_audio = video.getbestaudio()\n",
    "\n",
    "#         # Temporary filename\n",
    "#         temp_filename = 'temp_audio.' + best_audio.extension\n",
    "\n",
    "#         # Download the audio stream to a temporary file\n",
    "#         best_audio.download(filepath=temp_filename)\n",
    "\n",
    "#         # Convert the downloaded file to MP3\n",
    "#         clip = mp.AudioFileClip(temp_filename)\n",
    "#         clip.write_audiofile(output_path)\n",
    "\n",
    "#         # Close the clip to free resources\n",
    "#         clip.close()\n",
    "\n",
    "#         # Remove the temporary file\n",
    "#         os.remove(temp_filename)\n",
    "\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'output/testing.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_youtube_audio(youtube_url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytube\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt = pytube.YouTube(\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# import ffmpeg\n",
    "\n",
    "# text = 'https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan'\n",
    "\n",
    "# yt = YouTube(text)\n",
    "\n",
    "# # https://github.com/pytube/pytube/issues/301\n",
    "# stream_url = yt.streams.all()[0].url  # Get the URL of the video stream\n",
    "\n",
    "# # Probe the audio streams (use it in case you need information like sample rate):\n",
    "# #probe = ffmpeg.probe(stream_url)\n",
    "# #audio_streams = next((stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
    "# #sample_rate = audio_streams['sample_rate']\n",
    "\n",
    "# # Read audio into memory buffer.\n",
    "# # Get the audio using stdout pipe of ffmpeg sub-process.\n",
    "# # The audio is transcoded to PCM codec in WAC container.\n",
    "# audio, err = (\n",
    "#     ffmpeg\n",
    "#     .input(stream_url)\n",
    "#     .output(\"pipe:\", format='wav', acodec='pcm_s16le')  # Select WAV output format, and pcm_s16le auidio codec. My add ar=sample_rate\n",
    "#     .run(capture_stdout=True)\n",
    "# )\n",
    "\n",
    "# # Write the audio buffer to file for testing\n",
    "# with open('audio.wav', 'wb') as f:\n",
    "#     f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s'\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Path to ffmpeg binary\n",
    "#         ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "# ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "# with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#     ydl.download([\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Get the ffmpeg binary path from imageio_ffmpeg\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path,\n",
    "#             'verbose': True  # Enable verbose logging for debugging\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Working below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking  e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win64-v4.2.2.exe\n",
      "Download and conversion complete. File saved as audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "def download_youtube_audio(youtube_url, output_path):\n",
    "    try:\n",
    "        # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "        print(\"checking \", ffmpeg_path)\n",
    "        # Construct the yt-dlp command\n",
    "        cmd = [\n",
    "            'yt-dlp',\n",
    "            '-x',  # Extract audio only\n",
    "            '--audio-format', 'mp3',\n",
    "            '--ffmpeg-location', ffmpeg_path,\n",
    "            '-o', output_path,  # Output file template\n",
    "            youtube_url  # YouTube video URL\n",
    "        ]\n",
    "\n",
    "        # Run the command using subprocess\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            print(\"checking resturn.returncode \", result.returncode)\n",
    "            print(f\"Error occurred: {result.stderr}\")\n",
    "        else:\n",
    "            print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error checking \")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=x7X9w_GIm1s&ab_channel=Fireship\"\n",
    "\n",
    "# Output path for the converted MP3 file\n",
    "output_path = 'extracted_audio/audio.mp3'\n",
    "\n",
    "download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import yt_dlp\n",
    "\n",
    "# def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "#     try:\n",
    "#         # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # Create output directory if it doesn't exist\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "\n",
    "#         # Options to retrieve video info from playlist\n",
    "#         ydl_opts = {\n",
    "#             'quiet': True,\n",
    "#             'extract_flat': True,\n",
    "#             'force_generic_extractor': True,\n",
    "#         }\n",
    "\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             playlist_info = ydl.extract_info(playlist_url, download=False)\n",
    "\n",
    "#         # Check if the URL is a playlist and has entries\n",
    "#         if 'entries' not in playlist_info:\n",
    "#             print(\"The provided URL is not a playlist or has no entries.\")\n",
    "#             return\n",
    "\n",
    "#         # Iterate through each video in the playlist\n",
    "#         for index, entry in enumerate(playlist_info['entries'], start=1):\n",
    "#             video_url = entry['url']\n",
    "#             output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "#             # Construct the yt-dlp command\n",
    "#             cmd = [\n",
    "#                 'yt-dlp',\n",
    "#                 '-x',  # Extract audio only\n",
    "#                 '--audio-format', 'mp3',\n",
    "#                 '--ffmpeg-location', ffmpeg_path,\n",
    "#                 '-o', output_path,  # Output file template\n",
    "#                 video_url  # YouTube video URL\n",
    "#             ]\n",
    "\n",
    "#             # Run the command using subprocess\n",
    "#             result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#             # Check for errors\n",
    "#             if result.returncode != 0:\n",
    "#                 print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "#             else:\n",
    "#                 print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube playlist URL\n",
    "# playlist_url = \"https://youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR&si=bJn2d1cvuOlb10qC\"\n",
    "\n",
    "# # Output directory for the converted MP3 files\n",
    "# output_dir = 'extracted_audio'\n",
    "\n",
    "# download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For playlist download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'list'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AA\\AppData\\Local\\Temp\\ipykernel_15156\\4028681533.py\", line 17, in download_youtube_audio_playlist\n",
      "    video_urls = [video.watch_url for video in playlist.videos]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 296, in videos_generator\n",
      "    for url in self.video_urls:\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 281, in url_generator\n",
      "    for page in self._paginate():\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 118, in _paginate\n",
      "    json.dumps(extract.initial_data(self.html))\n",
      "                                    ^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 58, in html\n",
      "    self._html = request.get(self.playlist_url)\n",
      "                             ^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 48, in playlist_url\n",
      "    return f\"https://www.youtube.com/playlist?list={self.playlist_id}\"\n",
      "                                                    ^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 39, in playlist_id\n",
      "    self._playlist_id = extract.playlist_id(self._input_url)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\extract.py\", line 151, in playlist_id\n",
      "    return parse_qs(parsed.query)['list'][0]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "KeyError: 'list'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "from pytube import Playlist\n",
    "\n",
    "def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "    try:\n",
    "        # Path to ffmpeg executable\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Get video URLs from the playlist using pytube\n",
    "        playlist = Playlist(playlist_url)\n",
    "        video_urls = [video.watch_url for video in playlist.videos]\n",
    "\n",
    "        # Iterate through each video in the playlist\n",
    "        for index, video_url in enumerate(video_urls, start=1):\n",
    "            output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "            # Construct the yt-dlp command\n",
    "            cmd = [\n",
    "                'yt-dlp',\n",
    "                '-x',  # Extract audio only\n",
    "                '--audio-format', 'mp3',\n",
    "                '--ffmpeg-location', ffmpeg_path,\n",
    "                '-o', output_path,  # Output file template\n",
    "                video_url  # YouTube video URL\n",
    "            ]\n",
    "\n",
    "            # Run the command using subprocess\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            # Check for errors\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "            else:\n",
    "                print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube playlist URL\n",
    "playlist_url = \"https://www.youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR\"\n",
    "\n",
    "# Output directory for the converted MP3 files\n",
    "output_dir = 'extracted_audio'\n",
    "\n",
    "download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Transcript Vosk is working very poor trying to shift to deepspeesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import json\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model):\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     print(\"checking wf \", wf)\n",
    "#     rec = KaldiRecognizer(model, wf.getframerate())\n",
    "#     rec.SetWords(True)\n",
    "#     results = []\n",
    "#     while True:\n",
    "#         data = wf.readframes(4000)\n",
    "#         if len(data) == 0:\n",
    "#             break\n",
    "#         if rec.AcceptWaveform(data):\n",
    "#             results.append(json.loads(rec.Result()))\n",
    "#         else:\n",
    "#             results.append(json.loads(rec.PartialResult()))\n",
    "#     results.append(json.loads(rec.FinalResult()))\n",
    "#     text = ' '.join([res['text'] for res in results if 'text' in res])\n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     # Verify model path\n",
    "#     if not os.path.exists(model_path):\n",
    "#         raise Exception(f\"Model path {model_path} does not exist. Please check the path and try again.\")\n",
    "    \n",
    "#     print(f\"Loading Vosk model from {model_path}...\")\n",
    "\n",
    "#     try:\n",
    "#         print(\"model creation checking \")\n",
    "#         # Load the Vosk model\n",
    "#         model = Model(model_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to create a model from the path {model_path}. Error: {e}\")\n",
    "#         return\n",
    "\n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/vosk-model-en-us-0.42-gigaspeech'  # Replace with your Vosk model path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DeepSpeech by Mozila taking too much time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepSpeech model from audio_model/deepspeech-0.9.3-models.pbmm...\n",
      "Loading DeepSpeech scorer from audio_model/deepspeech-0.9.3-models.scorer...\n",
      "checking audio load  <pydub.audio_segment.AudioSegment object at 0x000001C2AD27A130>\n",
      "Converted extracted_audio\\audio.mp3 to transcription_results\\audio1.wav\n",
      "Starting transcription for transcription_results\\audio1.wav...\n",
      "Enabling scorer...\n",
      "Running model.stt...\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import numpy as np\n",
    "# import deepspeech\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model, scorer):\n",
    "#     print(f\"Starting transcription for {wav_file_path}...\")\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     fs = wf.getframerate()\n",
    "#     audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "    \n",
    "#     print(\"Enabling scorer...\")\n",
    "#     model.enableExternalScorer(scorer)\n",
    "#     print(\"Running model.stt...\")\n",
    "#     text = model.stt(audio)\n",
    "    \n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path, scorer_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "    \n",
    "#     print(f\"Loading DeepSpeech model from {model_path}...\")\n",
    "#     model = deepspeech.Model(model_path)\n",
    "#     print(f\"Loading DeepSpeech scorer from {scorer_path}...\")\n",
    "#     model.enableExternalScorer(scorer_path)\n",
    "    \n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model, scorer_path)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/deepspeech-0.9.3-models.pbmm'  # Replace with your DeepSpeech model path\n",
    "# scorer_path = 'audio_model/deepspeech-0.9.3-models.scorer'  # Replace with your DeepSpeech scorer path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path, scorer_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using amazon Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket audiootextai already exists.\n",
      "File extracted_audio/audio1.mp3 uploaded to S3 bucket audiootextai with key audio1.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcript downloaded to transcription_results/transcript1.json\n",
      "Transcript saved to transcription_results/transcript1.txt\n",
      "File extracted_audio/audio2.mp3 uploaded to S3 bucket audiootextai with key audio2.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcript downloaded to transcription_results/transcript2.json\n",
      "Transcript saved to transcription_results/transcript2.txt\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize Boto3 clients\n",
    "# Use a specific profile\n",
    "session = boto3.Session(profile_name='default')\n",
    "s3_client = session.client('s3')\n",
    "transcribe_client = session.client('transcribe')\n",
    "\n",
    "# Constants\n",
    "bucket_name = 'audiootextai'  # Replace with your S3 bucket name\n",
    "region = 'us-east-1'  # Replace with your AWS region\n",
    "\n",
    "def create_s3_bucket(bucket_name, region):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket {bucket_name} created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket {bucket_name}: {e}\")\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, s3_key):\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"File {file_path} uploaded to S3 bucket {bucket_name} with key {s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "def start_transcription_job(job_name, s3_uri, language_code='en-US'):\n",
    "    try:\n",
    "        response = transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': s3_uri},\n",
    "            MediaFormat='mp3',\n",
    "            LanguageCode=language_code,\n",
    "            OutputBucketName=bucket_name\n",
    "        )\n",
    "        print(f\"Started transcription job with name: {job_name}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting transcription job: {e}\")\n",
    "\n",
    "def get_transcription_result(job_name):\n",
    "    while True:\n",
    "        response = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if status in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        print(f\"Transcription job {job_name} status: {status}\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    if status == 'COMPLETED':\n",
    "        transcript_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "        print(f\"Transcription completed. Transcript URI: {transcript_uri}\")\n",
    "        return transcript_uri\n",
    "    else:\n",
    "        print(f\"Transcription job {job_name} failed.\")\n",
    "        return None\n",
    "\n",
    "def download_transcript(transcript_uri, output_path):\n",
    "    try:\n",
    "        response = requests.get(transcript_uri)\n",
    "        response.raise_for_status()\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Transcript downloaded to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading transcript: {e}\")\n",
    "\n",
    "def extract_transcript_from_file(json_file_path, output_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            # Extracting the transcript text\n",
    "            transcript_text = data['results']['transcripts'][0]['transcript']\n",
    "            \n",
    "            # Save the clean transcript to a text file\n",
    "            with open(output_file_path, 'w') as text_file:\n",
    "                text_file.write(transcript_text)\n",
    "            print(f\"Transcript saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {json_file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    file_paths = ['extracted_audio/audio1.mp3', 'extracted_audio/audio2.mp3']  # Replace with your list of MP3 file paths\n",
    "\n",
    "    # Check if the bucket exists and create it if not\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except:\n",
    "        print(f\"Bucket {bucket_name} does not exist. Creating bucket...\")\n",
    "        create_s3_bucket(bucket_name, region)\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('transcription_results', exist_ok=True)\n",
    "\n",
    "    for i, file_path in enumerate(file_paths, start=1):\n",
    "        s3_key = f'audio{i}.mp3'\n",
    "        job_name = f'transcription-job-{i}'\n",
    "        transcript_output_path = f'transcription_results/transcript{i}.json'\n",
    "        clean_text_output_path = f'transcription_results/transcript{i}.txt'\n",
    "\n",
    "        # Upload the file to S3\n",
    "        upload_file_to_s3(file_path, bucket_name, s3_key)\n",
    "\n",
    "        # Start transcription job\n",
    "        s3_uri = f's3://{bucket_name}/{s3_key}'\n",
    "        start_transcription_job(job_name, s3_uri)\n",
    "\n",
    "        # Get transcription result\n",
    "        transcript_uri = get_transcription_result(job_name)\n",
    "        if transcript_uri:\n",
    "            print(f\"Transcription result available at: {transcript_uri}\")\n",
    "            # Download the transcription result\n",
    "            download_transcript(transcript_uri, transcript_output_path)\n",
    "            # Extract clean text and save to file\n",
    "            extract_transcript_from_file(transcript_output_path, clean_text_output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma db setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\utils\\hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\Projects_working\\Audio_transcript\\embedding_model\\models--intfloat--e5-large-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = './embedding_model'\n",
    "\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# # from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_text_splitters.character import CharacterTextSplitter\n",
    "\n",
    "# persist_directory = './chroma_db'\n",
    "\n",
    "# transcription_dir = \"./transcription_results\"\n",
    "# for file_name in os.listdir(transcription_dir):\n",
    "#         if file_name.endswith('.txt'):\n",
    "#             file_path = os.path.join(transcription_dir, file_name)\n",
    "#             loader = TextLoader(file_path)\n",
    "#             documents = loader.load()\n",
    "#             text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "#             docs = text_splitter.split_documents(documents)\n",
    "#             hf_embeddings.embed_documents(docs)\n",
    "\n",
    "# vectordb = Chroma.from_documents(documents=docs, embedding=hf_embedding, persist_directory=persist_directory)\n",
    "# # persiste the db to disk\n",
    "# vectordb.persist()\n",
    "\n",
    "# retriever = vectordb.as_retriever()\n",
    "# query = \"Kamala Harris performs about the same, maybe a little better nationally up against Donald Trump.\"\n",
    "# docs = retriever.get_relevant_documents(query)\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know, it all comes down to the polls. We know that President Biden wanted to see some of this data. Kamala Harris performs about the same, maybe a little better nationally up against Donald Trump. There are some bright spots I think on the democratic side for the Democrats and some of the battlegrounds but make no mistake. The numbers that I've seen show that she has a very stiff challenge ahead if she's the nominee in these key battlegrounds. That's exactly right, David, this does not solve all of Democrats, the Democrats problems. In fact, it could make them worse in some states. If you believe the very early battleground state polls, there hasn't been much out there. We have seen a national poll that came out just in the couple of the last couple of days that had a dead tie between Joe Biden. I'm sorry, between Donald Trump and Kamala Harris. And we also had some new polling out today from ABC news and IPSOS that showed favorability ratings for some of the major candidates check that out. Kamala Harris's number a little bit better than Joe Biden, but not as good as Donald Trump. Trump got a significant boost out of his convention and out of the assassination attempt. So these numbers still have to be concerning to Democrats, but they've got a lot of time to try to build up Harris. And it was significant in your interview with Donna right there that they are going to continue to push to have virtual roll call ahead of the national convention. The deadline is actually going to be August 7th according to Donna, who is part of the Democratic National Committee that pushes things up and that tells you some of the urgency now among Democrats, they want to get this squared away to stop any challenges that could happen on the convention floor that remains the plan of the Democratic National Committee at this hour to try to get this all wrapped up in a bowl before they arrive in Chicago. That is going to be a tough task with Senator Manchin and others circling about other opportunities. We\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "\n",
    "# Directory for Chroma database\n",
    "persist_directory = './chroma_db'\n",
    "\n",
    "# Directory containing transcription results\n",
    "transcription_dir = \"./transcription_results\"\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# Load and process documents\n",
    "for file_name in os.listdir(transcription_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(transcription_dir, file_name)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "# Initialize Chroma vector database with the documents\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding=hf_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python, a high level interpreted programming language famous for its Zen Light code. It's arguably the most popular language in the world because it's easy to learn yet practical for serious projects. In fact, you're watching this youtube video in a Python web application right now. It was created by Guido Van Rossum and released in 1991 who named it after Monty Python's Flying Circus, which is why you'll sometimes find spam and eggs instead of foo and bar and code samples. It's commonly used to build server site application like web apps with the Django framework and is the language of choice for big data analysis and machine learning. Many students choose Python to start learning to code because of its emphasis on readability. As outlined by the Zen of Python, beautiful is better than ugly while explicit is better than implicit. Python is very simple but avoids the temptation to Sprinkle in magic that causes ambiguity. Its code is often organized into notebooks where individual cells can be executed then documented in the same place. We're currently version three of the language and you can get started by creating a file that ends in dot Py or do IP Y and B to create an interactive notebook, create a variable by setting a name equal to a value it's strongly typed, which means values won't change in unexpected ways but dynamic. So type annotations are not required. The syntax is highly efficient allowing you to declare multiple variables on a single line and define tuples lists and dictionaries with a literal syntax, semicolons are not required. And if you use them and experience Python will say that your code is not Python instead of semicolons. Python uses indentation to terminate or determine the scope of a line of code, define a function with a de keyword, then indent the next line usually by four spaces to define the function body, we might then add a four loop to it and indent that by another four spaces. This eliminates the need for curly braces and semicolons found in many other languages. Python is a multi paradigm language. We can apply functional programming patterns with things like anonymous functions using lambda also uses objects as an abstraction for data allowing you to implement object oriented patterns with things like classes and inheritance. It also has a huge ecosystem of third party libraries such as deep learning frameworks like tensorflow and wrappers for many high performance low level packages like open computer vision which are most often installed with the PIP package manager. This has been the Python programming language in 100 seconds, hit the like button if you want to see more short videos like this. Thanks for watching and I will see you in the next one.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the most popular language in the world?\"\n",
    "# docs = retriever.get_relevant_documents(query)\n",
    "result = vectordb.similarity_search(query)\n",
    "\n",
    "# Print the content of the first relevant document\n",
    "if result:\n",
    "    print(result[0].page_content)\n",
    "else:\n",
    "    print(\"No relevant documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3 setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m llama_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantFactory/Meta-Llama-3-70B-Instruct-GGUF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m llama_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mllama_model_id,\n\u001b[0;32m      5\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mbfloat16},\n\u001b[0;32m      6\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(context, question):\n\u001b[0;32m     10\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a pirate chatbot who always responds in pirate speak!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m question},\n\u001b[0;32m     13\u001b[0m     ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# llama_model_id = \"QuantFactory/Meta-Llama-3-70B-Instruct-GGUF\"\n",
    "# llama_pipeline = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=llama_model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device=\"auto\",\n",
    "# )\n",
    "\n",
    "# def generate_response(context, question):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpfull assistant\"},\n",
    "#         {\"role\": \"user\", \"content\": context + \"\\n\" + question},\n",
    "#     ]\n",
    "#     prompt = llama_pipeline.tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         tokenize=False,\n",
    "#         add_generation_prompt=True\n",
    "#     )\n",
    "#     terminators = [\n",
    "#         llama_pipeline.tokenizer.eos_token_id,\n",
    "#         llama_pipeline.tokenizer.convert_tokens_to_ids(\"\")\n",
    "#     ]\n",
    "#     outputs = llama_pipeline(\n",
    "#         prompt,\n",
    "#         max_new_tokens=256,\n",
    "#         eos_token_id=terminators,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.6,\n",
    "#         top_p=0.9,\n",
    "#     )\n",
    "#     return outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "# def answer_question(question):\n",
    "#     docs = db.similarity_search(question)\n",
    "#     context = \" \".join([doc.page_content for doc in docs])\n",
    "#     response = generate_response(context, question)\n",
    "#     return response\n",
    "\n",
    "# # Example usage\n",
    "# question = \"What is the main topic of the first lecture?\"\n",
    "# answer = answer_question(question)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "accelerate is required when loading a GGUF file `pip install accelerate`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta-Llama-3-8B-Instruct-v2.Q4_0.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, gguf_file\u001b[38;5;241m=\u001b[39mfilename)\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32me:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\modeling_utils.py:3123\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3117\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   3118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3120\u001b[0m     )\n\u001b[0;32m   3122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 3123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerate is required when loading a GGUF file `pip install accelerate`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   3127\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: accelerate is required when loading a GGUF file `pip install accelerate`."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = './llm_model'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "filename = \"Meta-Llama-3-8B-Instruct-v2.Q4_0.gguf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, gguf_file=filename)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, gguf_file=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_chroma import Chroma\n",
    "from transformers import pipeline, GPTQConfig\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding=hf_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "{history}\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "# Setup ConversationalRetrievalChain\n",
    "memory = ConversationBufferWindowMemory(k=5, return_messages=True)\n",
    "retriever = vectordb.as_retriever()\n",
    "conversational_retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "chat_response = conversational_retrieval_chain.invoke({\"question\": \"input_text\"})\n",
    "\n",
    "print(chat_response['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
