{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# from moviepy.editor import *\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import yt_dlp\n",
    "# from yt_dlp import YoutubeDL\n",
    "# import moviepy.editor as mp\n",
    "\n",
    "# # Set yt-dlp as the backend for pafy\n",
    "# os.environ[\"PYPYDL_PYPI_PACKAGE\"] = \"yt-dlp\"\n",
    "\n",
    "# # Create a YoutubeDL instance and set it to the pafy backend\n",
    "# def new_pafy_backend():\n",
    "#     yt_dlp_options = {'format': 'bestaudio/best'}\n",
    "#     return YoutubeDL(yt_dlp_options)\n",
    "\n",
    "# pafy.backend_shared.backend = new_pafy_backend()\n",
    "\n",
    "# import pafy\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Create a pafy object\n",
    "#         video = pafy.new(youtube_url)\n",
    "\n",
    "#         # Select the best audio stream\n",
    "#         best_audio = video.getbestaudio()\n",
    "\n",
    "#         # Temporary filename\n",
    "#         temp_filename = 'temp_audio.' + best_audio.extension\n",
    "\n",
    "#         # Download the audio stream to a temporary file\n",
    "#         best_audio.download(filepath=temp_filename)\n",
    "\n",
    "#         # Convert the downloaded file to MP3\n",
    "#         clip = mp.AudioFileClip(temp_filename)\n",
    "#         clip.write_audiofile(output_path)\n",
    "\n",
    "#         # Close the clip to free resources\n",
    "#         clip.close()\n",
    "\n",
    "#         # Remove the temporary file\n",
    "#         os.remove(temp_filename)\n",
    "\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'output/testing.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_youtube_audio(youtube_url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytube\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt = pytube.YouTube(\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# import ffmpeg\n",
    "\n",
    "# text = 'https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan'\n",
    "\n",
    "# yt = YouTube(text)\n",
    "\n",
    "# # https://github.com/pytube/pytube/issues/301\n",
    "# stream_url = yt.streams.all()[0].url  # Get the URL of the video stream\n",
    "\n",
    "# # Probe the audio streams (use it in case you need information like sample rate):\n",
    "# #probe = ffmpeg.probe(stream_url)\n",
    "# #audio_streams = next((stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
    "# #sample_rate = audio_streams['sample_rate']\n",
    "\n",
    "# # Read audio into memory buffer.\n",
    "# # Get the audio using stdout pipe of ffmpeg sub-process.\n",
    "# # The audio is transcoded to PCM codec in WAC container.\n",
    "# audio, err = (\n",
    "#     ffmpeg\n",
    "#     .input(stream_url)\n",
    "#     .output(\"pipe:\", format='wav', acodec='pcm_s16le')  # Select WAV output format, and pcm_s16le auidio codec. My add ar=sample_rate\n",
    "#     .run(capture_stdout=True)\n",
    "# )\n",
    "\n",
    "# # Write the audio buffer to file for testing\n",
    "# with open('audio.wav', 'wb') as f:\n",
    "#     f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s'\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Path to ffmpeg binary\n",
    "#         ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg_path = r'C:\\Users\\AA\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "# ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "# with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#     ydl.download([\"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yt_dlp\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import os\n",
    "\n",
    "# def download_youtube_audio(youtube_url, output_path):\n",
    "#     try:\n",
    "#         # Get the ffmpeg binary path from imageio_ffmpeg\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # yt-dlp options to extract audio and convert to mp3\n",
    "#         ydl_opts = {\n",
    "#             'format': 'bestaudio/best',\n",
    "#             'postprocessors': [{\n",
    "#                 'key': 'FFmpegExtractAudio',\n",
    "#                 'preferredcodec': 'mp3',\n",
    "#                 'preferredquality': '192',\n",
    "#             }],\n",
    "#             'outtmpl': 'temp_audio.%(ext)s',\n",
    "#             'ffmpeg_location': ffmpeg_path,\n",
    "#             'verbose': True  # Enable verbose logging for debugging\n",
    "#         }\n",
    "\n",
    "#         # Download the audio using yt-dlp\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             ydl.download([youtube_url])\n",
    "\n",
    "#         # Rename the downloaded file to the output path\n",
    "#         temp_filename = 'temp_audio.mp3'\n",
    "#         os.rename(temp_filename, output_path)\n",
    "#         print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube URL\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=opNYFJ5SO10&ab_channel=CodingWithEvan\"\n",
    "\n",
    "# # Output path for the converted MP3 file\n",
    "# output_path = 'audio.mp3'\n",
    "\n",
    "# download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Working below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking  e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win64-v4.2.2.exe\n",
      "Download and conversion complete. File saved as audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "def download_youtube_audio(youtube_url, output_path):\n",
    "    try:\n",
    "        # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "        print(\"checking \", ffmpeg_path)\n",
    "        # Construct the yt-dlp command\n",
    "        cmd = [\n",
    "            'yt-dlp',\n",
    "            '-x',  # Extract audio only\n",
    "            '--audio-format', 'mp3',\n",
    "            '--ffmpeg-location', ffmpeg_path,\n",
    "            '-o', output_path,  # Output file template\n",
    "            youtube_url  # YouTube video URL\n",
    "        ]\n",
    "\n",
    "        # Run the command using subprocess\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            print(\"checking resturn.returncode \", result.returncode)\n",
    "            print(f\"Error occurred: {result.stderr}\")\n",
    "        else:\n",
    "            print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error checking \")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=x7X9w_GIm1s&ab_channel=Fireship\"\n",
    "\n",
    "# Output path for the converted MP3 file\n",
    "output_path = 'extracted_audio/audio.mp3'\n",
    "\n",
    "download_youtube_audio(youtube_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "# import imageio_ffmpeg as ffmpeg\n",
    "# import yt_dlp\n",
    "\n",
    "# def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "#     try:\n",
    "#         # Path to ffmpeg executable (if necessary, otherwise ffmpeg should be in PATH)\n",
    "#         ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "#         # Create output directory if it doesn't exist\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "\n",
    "#         # Options to retrieve video info from playlist\n",
    "#         ydl_opts = {\n",
    "#             'quiet': True,\n",
    "#             'extract_flat': True,\n",
    "#             'force_generic_extractor': True,\n",
    "#         }\n",
    "\n",
    "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#             playlist_info = ydl.extract_info(playlist_url, download=False)\n",
    "\n",
    "#         # Check if the URL is a playlist and has entries\n",
    "#         if 'entries' not in playlist_info:\n",
    "#             print(\"The provided URL is not a playlist or has no entries.\")\n",
    "#             return\n",
    "\n",
    "#         # Iterate through each video in the playlist\n",
    "#         for index, entry in enumerate(playlist_info['entries'], start=1):\n",
    "#             video_url = entry['url']\n",
    "#             output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "#             # Construct the yt-dlp command\n",
    "#             cmd = [\n",
    "#                 'yt-dlp',\n",
    "#                 '-x',  # Extract audio only\n",
    "#                 '--audio-format', 'mp3',\n",
    "#                 '--ffmpeg-location', ffmpeg_path,\n",
    "#                 '-o', output_path,  # Output file template\n",
    "#                 video_url  # YouTube video URL\n",
    "#             ]\n",
    "\n",
    "#             # Run the command using subprocess\n",
    "#             result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#             # Check for errors\n",
    "#             if result.returncode != 0:\n",
    "#                 print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "#             else:\n",
    "#                 print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Example YouTube playlist URL\n",
    "# playlist_url = \"https://youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR&si=bJn2d1cvuOlb10qC\"\n",
    "\n",
    "# # Output directory for the converted MP3 files\n",
    "# output_dir = 'extracted_audio'\n",
    "\n",
    "# download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For playlist download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'list'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AA\\AppData\\Local\\Temp\\ipykernel_15156\\4028681533.py\", line 17, in download_youtube_audio_playlist\n",
      "    video_urls = [video.watch_url for video in playlist.videos]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 296, in videos_generator\n",
      "    for url in self.video_urls:\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 71, in __iter__\n",
      "    curr_item = self[iter_index]\n",
      "                ~~~~^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\helpers.py\", line 57, in __getitem__\n",
      "    next_item = next(self.gen)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 281, in url_generator\n",
      "    for page in self._paginate():\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 118, in _paginate\n",
      "    json.dumps(extract.initial_data(self.html))\n",
      "                                    ^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 58, in html\n",
      "    self._html = request.get(self.playlist_url)\n",
      "                             ^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 48, in playlist_url\n",
      "    return f\"https://www.youtube.com/playlist?list={self.playlist_id}\"\n",
      "                                                    ^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\contrib\\playlist.py\", line 39, in playlist_id\n",
      "    self._playlist_id = extract.playlist_id(self._input_url)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Projects_working\\Audio_transcript\\.venv\\Lib\\site-packages\\pytube\\extract.py\", line 151, in playlist_id\n",
      "    return parse_qs(parsed.query)['list'][0]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "KeyError: 'list'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "from pytube import Playlist\n",
    "\n",
    "def download_youtube_audio_playlist(playlist_url, output_dir):\n",
    "    try:\n",
    "        # Path to ffmpeg executable\n",
    "        ffmpeg_path = ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Get video URLs from the playlist using pytube\n",
    "        playlist = Playlist(playlist_url)\n",
    "        video_urls = [video.watch_url for video in playlist.videos]\n",
    "\n",
    "        # Iterate through each video in the playlist\n",
    "        for index, video_url in enumerate(video_urls, start=1):\n",
    "            output_path = os.path.join(output_dir, f'audio{index}.mp3')\n",
    "\n",
    "            # Construct the yt-dlp command\n",
    "            cmd = [\n",
    "                'yt-dlp',\n",
    "                '-x',  # Extract audio only\n",
    "                '--audio-format', 'mp3',\n",
    "                '--ffmpeg-location', ffmpeg_path,\n",
    "                '-o', output_path,  # Output file template\n",
    "                video_url  # YouTube video URL\n",
    "            ]\n",
    "\n",
    "            # Run the command using subprocess\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            # Check for errors\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error occurred for {video_url}: {result.stderr}\")\n",
    "            else:\n",
    "                print(f\"Download and conversion complete. File saved as {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example YouTube playlist URL\n",
    "playlist_url = \"https://www.youtube.com/playlist?list=PLI-hcKnojs-hM3Dtec1kyP2gym7sghNFR\"\n",
    "\n",
    "# Output directory for the converted MP3 files\n",
    "output_dir = 'extracted_audio'\n",
    "\n",
    "download_youtube_audio_playlist(playlist_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Transcript Vosk is working very poor trying to shift to deepspeesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import json\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model):\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     print(\"checking wf \", wf)\n",
    "#     rec = KaldiRecognizer(model, wf.getframerate())\n",
    "#     rec.SetWords(True)\n",
    "#     results = []\n",
    "#     while True:\n",
    "#         data = wf.readframes(4000)\n",
    "#         if len(data) == 0:\n",
    "#             break\n",
    "#         if rec.AcceptWaveform(data):\n",
    "#             results.append(json.loads(rec.Result()))\n",
    "#         else:\n",
    "#             results.append(json.loads(rec.PartialResult()))\n",
    "#     results.append(json.loads(rec.FinalResult()))\n",
    "#     text = ' '.join([res['text'] for res in results if 'text' in res])\n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     # Verify model path\n",
    "#     if not os.path.exists(model_path):\n",
    "#         raise Exception(f\"Model path {model_path} does not exist. Please check the path and try again.\")\n",
    "    \n",
    "#     print(f\"Loading Vosk model from {model_path}...\")\n",
    "\n",
    "#     try:\n",
    "#         print(\"model creation checking \")\n",
    "#         # Load the Vosk model\n",
    "#         model = Model(model_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to create a model from the path {model_path}. Error: {e}\")\n",
    "#         return\n",
    "\n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/vosk-model-en-us-0.42-gigaspeech'  # Replace with your Vosk model path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DeepSpeech by Mozila taking too much time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepSpeech model from audio_model/deepspeech-0.9.3-models.pbmm...\n",
      "Loading DeepSpeech scorer from audio_model/deepspeech-0.9.3-models.scorer...\n",
      "checking audio load  <pydub.audio_segment.AudioSegment object at 0x000001C2AD27A130>\n",
      "Converted extracted_audio\\audio.mp3 to transcription_results\\audio1.wav\n",
      "Starting transcription for transcription_results\\audio1.wav...\n",
      "Enabling scorer...\n",
      "Running model.stt...\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "# import wave\n",
    "# import numpy as np\n",
    "# import deepspeech\n",
    "\n",
    "# def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "#     audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "#     print(\"checking audio load \", audio)\n",
    "#     audio.export(wav_file_path, format=\"wav\")\n",
    "#     print(f\"Converted {mp3_file_path} to {wav_file_path}\")\n",
    "\n",
    "# def transcribe_audio(wav_file_path, model, scorer):\n",
    "#     print(f\"Starting transcription for {wav_file_path}...\")\n",
    "#     wf = wave.open(wav_file_path, \"rb\")\n",
    "#     fs = wf.getframerate()\n",
    "#     audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "    \n",
    "#     print(\"Enabling scorer...\")\n",
    "#     model.enableExternalScorer(scorer)\n",
    "#     print(\"Running model.stt...\")\n",
    "#     text = model.stt(audio)\n",
    "    \n",
    "#     print(f\"Transcription for {wav_file_path}:\")\n",
    "#     print(text)\n",
    "#     return text\n",
    "\n",
    "# def process_audio_files(input_dir, output_dir, model_path, scorer_path):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "    \n",
    "#     print(f\"Loading DeepSpeech model from {model_path}...\")\n",
    "#     model = deepspeech.Model(model_path)\n",
    "#     print(f\"Loading DeepSpeech scorer from {scorer_path}...\")\n",
    "#     model.enableExternalScorer(scorer_path)\n",
    "    \n",
    "#     for index, audio_file in enumerate(os.listdir(input_dir), start=1):\n",
    "#         if audio_file.endswith('.mp3'):\n",
    "#             mp3_file_path = os.path.join(input_dir, audio_file)\n",
    "#             wav_file_path = os.path.join(output_dir, f'audio{index}.wav')\n",
    "#             convert_mp3_to_wav(mp3_file_path, wav_file_path)\n",
    "#             transcription = transcribe_audio(wav_file_path, model, scorer_path)\n",
    "#             text_file_path = os.path.join(output_dir, f'textfile{index}.txt')\n",
    "#             with open(text_file_path, 'w') as f:\n",
    "#                 f.write(transcription)\n",
    "#             print(f\"Transcription saved to {text_file_path}\")\n",
    "\n",
    "# # Directories\n",
    "# input_dir = 'extracted_audio'\n",
    "# output_dir = 'transcription_results'\n",
    "# model_path = 'audio_model/deepspeech-0.9.3-models.pbmm'  # Replace with your DeepSpeech model path\n",
    "# scorer_path = 'audio_model/deepspeech-0.9.3-models.scorer'  # Replace with your DeepSpeech scorer path\n",
    "\n",
    "# process_audio_files(input_dir, output_dir, model_path, scorer_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using amazon Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket audiootextai already exists.\n",
      "File extracted_audio/audio1.mp3 uploaded to S3 bucket audiootextai with key audio1.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-1.json\n",
      "Transcript downloaded to transcription_results/transcript1.json\n",
      "Transcript saved to transcription_results/transcript1.txt\n",
      "File extracted_audio/audio2.mp3 uploaded to S3 bucket audiootextai with key audio2.mp3\n",
      "Error starting transcription job: An error occurred (ConflictException) when calling the StartTranscriptionJob operation: The requested job name already exists. Use a different job name.\n",
      "Transcription completed. Transcript URI: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcription result available at: https://s3.us-east-1.amazonaws.com/audiootextai/transcription-job-2.json\n",
      "Transcript downloaded to transcription_results/transcript2.json\n",
      "Transcript saved to transcription_results/transcript2.txt\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize Boto3 clients\n",
    "# Use a specific profile\n",
    "session = boto3.Session(profile_name='default')\n",
    "s3_client = session.client('s3')\n",
    "transcribe_client = session.client('transcribe')\n",
    "\n",
    "# Constants\n",
    "bucket_name = 'audiootextai'  # Replace with your S3 bucket name\n",
    "region = 'us-east-1'  # Replace with your AWS region\n",
    "\n",
    "def create_s3_bucket(bucket_name, region):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket {bucket_name} created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket {bucket_name}: {e}\")\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, s3_key):\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"File {file_path} uploaded to S3 bucket {bucket_name} with key {s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "def start_transcription_job(job_name, s3_uri, language_code='en-US'):\n",
    "    try:\n",
    "        response = transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': s3_uri},\n",
    "            MediaFormat='mp3',\n",
    "            LanguageCode=language_code,\n",
    "            OutputBucketName=bucket_name\n",
    "        )\n",
    "        print(f\"Started transcription job with name: {job_name}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting transcription job: {e}\")\n",
    "\n",
    "def get_transcription_result(job_name):\n",
    "    while True:\n",
    "        response = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if status in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        print(f\"Transcription job {job_name} status: {status}\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    if status == 'COMPLETED':\n",
    "        transcript_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "        print(f\"Transcription completed. Transcript URI: {transcript_uri}\")\n",
    "        return transcript_uri\n",
    "    else:\n",
    "        print(f\"Transcription job {job_name} failed.\")\n",
    "        return None\n",
    "\n",
    "def download_transcript(transcript_uri, output_path):\n",
    "    try:\n",
    "        response = requests.get(transcript_uri)\n",
    "        response.raise_for_status()\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Transcript downloaded to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading transcript: {e}\")\n",
    "\n",
    "def extract_transcript_from_file(json_file_path, output_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            # Extracting the transcript text\n",
    "            transcript_text = data['results']['transcripts'][0]['transcript']\n",
    "            \n",
    "            # Save the clean transcript to a text file\n",
    "            with open(output_file_path, 'w') as text_file:\n",
    "                text_file.write(transcript_text)\n",
    "            print(f\"Transcript saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {json_file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    file_paths = ['extracted_audio/audio1.mp3', 'extracted_audio/audio2.mp3']  # Replace with your list of MP3 file paths\n",
    "\n",
    "    # Check if the bucket exists and create it if not\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except:\n",
    "        print(f\"Bucket {bucket_name} does not exist. Creating bucket...\")\n",
    "        create_s3_bucket(bucket_name, region)\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('transcription_results', exist_ok=True)\n",
    "\n",
    "    for i, file_path in enumerate(file_paths, start=1):\n",
    "        s3_key = f'audio{i}.mp3'\n",
    "        job_name = f'transcription-job-{i}'\n",
    "        transcript_output_path = f'transcription_results/transcript{i}.json'\n",
    "        clean_text_output_path = f'transcription_results/transcript{i}.txt'\n",
    "\n",
    "        # Upload the file to S3\n",
    "        upload_file_to_s3(file_path, bucket_name, s3_key)\n",
    "\n",
    "        # Start transcription job\n",
    "        s3_uri = f's3://{bucket_name}/{s3_key}'\n",
    "        start_transcription_job(job_name, s3_uri)\n",
    "\n",
    "        # Get transcription result\n",
    "        transcript_uri = get_transcription_result(job_name)\n",
    "        if transcript_uri:\n",
    "            print(f\"Transcription result available at: {transcript_uri}\")\n",
    "            # Download the transcription result\n",
    "            download_transcript(transcript_uri, transcript_output_path)\n",
    "            # Extract clean text and save to file\n",
    "            extract_transcript_from_file(transcript_output_path, clean_text_output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma db setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\utils\\hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\Projects_working\\Audio_transcript\\embedding_model\\models--intfloat--e5-large-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = './embedding_model'\n",
    "\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# # from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_text_splitters.character import CharacterTextSplitter\n",
    "\n",
    "# persist_directory = './chroma_db'\n",
    "\n",
    "# transcription_dir = \"./transcription_results\"\n",
    "# for file_name in os.listdir(transcription_dir):\n",
    "#         if file_name.endswith('.txt'):\n",
    "#             file_path = os.path.join(transcription_dir, file_name)\n",
    "#             loader = TextLoader(file_path)\n",
    "#             documents = loader.load()\n",
    "#             text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "#             docs = text_splitter.split_documents(documents)\n",
    "#             hf_embeddings.embed_documents(docs)\n",
    "\n",
    "# vectordb = Chroma.from_documents(documents=docs, embedding=hf_embedding, persist_directory=persist_directory)\n",
    "# # persiste the db to disk\n",
    "# vectordb.persist()\n",
    "\n",
    "# retriever = vectordb.as_retriever()\n",
    "# query = \"Kamala Harris performs about the same, maybe a little better nationally up against Donald Trump.\"\n",
    "# docs = retriever.get_relevant_documents(query)\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know, it all comes down to the polls. We know that President Biden wanted to see some of this data. Kamala Harris performs about the same, maybe a little better nationally up against Donald Trump. There are some bright spots I think on the democratic side for the Democrats and some of the battlegrounds but make no mistake. The numbers that I've seen show that she has a very stiff challenge ahead if she's the nominee in these key battlegrounds. That's exactly right, David, this does not solve all of Democrats, the Democrats problems. In fact, it could make them worse in some states. If you believe the very early battleground state polls, there hasn't been much out there. We have seen a national poll that came out just in the couple of the last couple of days that had a dead tie between Joe Biden. I'm sorry, between Donald Trump and Kamala Harris. And we also had some new polling out today from ABC news and IPSOS that showed favorability ratings for some of the major candidates check that out. Kamala Harris's number a little bit better than Joe Biden, but not as good as Donald Trump. Trump got a significant boost out of his convention and out of the assassination attempt. So these numbers still have to be concerning to Democrats, but they've got a lot of time to try to build up Harris. And it was significant in your interview with Donna right there that they are going to continue to push to have virtual roll call ahead of the national convention. The deadline is actually going to be August 7th according to Donna, who is part of the Democratic National Committee that pushes things up and that tells you some of the urgency now among Democrats, they want to get this squared away to stop any challenges that could happen on the convention floor that remains the plan of the Democratic National Committee at this hour to try to get this all wrapped up in a bowl before they arrive in Chicago. That is going to be a tough task with Senator Manchin and others circling about other opportunities. We\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "\n",
    "# Directory for Chroma database\n",
    "persist_directory = './chroma_db'\n",
    "\n",
    "# Directory containing transcription results\n",
    "transcription_dir = \"./transcription_results\"\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# Load and process documents\n",
    "for file_name in os.listdir(transcription_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(transcription_dir, file_name)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "# Initialize Chroma vector database with the documents\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding=hf_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"what is the most popular language in the world?\"\n",
    "# # docs = retriever.get_relevant_documents(query)\n",
    "# result = vectordb.similarity_search(query)\n",
    "\n",
    "# # Print the content of the first relevant document\n",
    "# if result:\n",
    "#     print(result[0].page_content)\n",
    "# else:\n",
    "#     print(\"No relevant documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3 setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# llama_model_id = \"QuantFactory/Meta-Llama-3-70B-Instruct-GGUF\"\n",
    "# llama_pipeline = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=llama_model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device=\"auto\",\n",
    "# )\n",
    "\n",
    "# def generate_response(context, question):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpfull assistant\"},\n",
    "#         {\"role\": \"user\", \"content\": context + \"\\n\" + question},\n",
    "#     ]\n",
    "#     prompt = llama_pipeline.tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         tokenize=False,\n",
    "#         add_generation_prompt=True\n",
    "#     )\n",
    "#     terminators = [\n",
    "#         llama_pipeline.tokenizer.eos_token_id,\n",
    "#         llama_pipeline.tokenizer.convert_tokens_to_ids(\"\")\n",
    "#     ]\n",
    "#     outputs = llama_pipeline(\n",
    "#         prompt,\n",
    "#         max_new_tokens=256,\n",
    "#         eos_token_id=terminators,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.6,\n",
    "#         top_p=0.9,\n",
    "#     )\n",
    "#     return outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "# def answer_question(question):\n",
    "#     docs = db.similarity_search(question)\n",
    "#     context = \" \".join([doc.page_content for doc in docs])\n",
    "#     response = generate_response(context, question)\n",
    "#     return response\n",
    "\n",
    "# # Example usage\n",
    "# question = \"What is the main topic of the first lecture?\"\n",
    "# answer = answer_question(question)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import os\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# os.environ['HF_HOME'] = './llm_model'\n",
    "# os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "# # Model and tokenizer setup\n",
    "# model_id = \"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "# filename = \"Meta-Llama-3-8B-Instruct-v2.Q4_0.gguf\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, gguf_file=filename)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, gguf_file=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"llm_model\\Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
    "\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import os\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# os.environ['HF_HOME'] = './llm_model'\n",
    "# os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# # Check if the model is loaded correctly\n",
    "# print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from ollama import OllamaModel, OllamaTokenizer\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# os.environ['OLLAMA_HOME'] = './llm_model'\n",
    "# os.environ['OLLAMA_CACHE'] = './llm_model'\n",
    "\n",
    "# # Path to the model files\n",
    "# model_id = \"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "# filename = \"Meta-Llama-3-8B-Instruct-v2.Q4_0.gguf\"\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# tokenizer = OllamaTokenizer.from_pretrained(model_id, cache_dir=\"./llm_model\")\n",
    "# model = OllamaModel.from_pretrained(model_id, gguf_file=filename, cache_dir=\"./llm_model\")\n",
    "\n",
    "# # Define a prompt for inference\n",
    "# prompt = \"What is the capital of France?\"\n",
    "\n",
    "# # Tokenize the prompt\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# # Generate a response\n",
    "# output = model.generate(input_ids=input_ids, max_length=50)\n",
    "\n",
    "# # Decode and print the response\n",
    "# response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "# print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "# import os\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# os.environ['HF_HOME'] = './llm_model'\n",
    "# os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "# # Model and tokenizer setup\n",
    "# model_id = \"openbmb/MiniCPM-Llama3-V-2_5-int4\"  # Example model ID for a non-quantized model\n",
    "# # If you have a quantized model, replace with the appropriate ID and filename\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from ctransformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# # os.environ['HF_HOME'] = './llm_model'\n",
    "# # os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "# # Model and tokenizer setup\n",
    "# model_id = \"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "# filename = \"Meta-Llama-3-8B-Instruct-v2.Q4_0.gguf\"\n",
    "\n",
    "# # Load the model and tokenizer using ctransformers\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(model_id, gguf_file=filename)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, model_file=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model(\"AI is going to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from ctransformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# # os.environ['HF_HOME'] = './llm_model'\n",
    "# # os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "# # Model and tokenizer setup\n",
    "# model_id = \"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "# filename = \"Meta-Llama-3-8B-Instruct-v2.Q4_0.gguf\"\n",
    "\n",
    "# # Load the model and tokenizer using ctransformers\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, model_file=filename)\n",
    "\n",
    "# # Function to generate text\n",
    "# def generate_text(model, tokenizer, prompt):\n",
    "#     input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "#     output = model.generate(input_ids)\n",
    "#     response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#     return response\n",
    "\n",
    "# # Test the model\n",
    "# prompt = \"hello\"\n",
    "# response = generate_text(model, tokenizer, prompt)\n",
    "# print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_cpp import Llama\n",
    "# import os\n",
    "\n",
    "# # Set environment variables for cache directories\n",
    "# # os.environ['LLAMA_HOME'] = './llm_model'\n",
    "\n",
    "# # Define the path to the GGUF model\n",
    "# model_path = \"E:\\HuggingFaceCache\\hub\\models--QuantFactory--Meta-Llama-3-8B-Instruct-GGUF-v2\"\n",
    "\n",
    "# # Load the model using Llama\n",
    "# llama = Llama(model_path)\n",
    "\n",
    "# # Define the prompt\n",
    "# prompt = \"You are a helpful assistant. What is the capital of France?\"\n",
    "\n",
    "# # Generate text from the model\n",
    "# response = llama(prompt)\n",
    "\n",
    "# # Print the response\n",
    "# print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# model_id = \"QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "# ]\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     messages,\n",
    "#     max_new_tokens=256,\n",
    "# )\n",
    "# print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# llm = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"llm_model/Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "#     model_type=\"llama-3\",\n",
    "# )\n",
    "\n",
    "# print(llm(\"Hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate text\n",
    "# prompt = \"You are a helpful assistant. Write a limerick about Python exceptions.\"\n",
    "# input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# # Generate the response\n",
    "# output = model.generate(input_ids, max_length=100)\n",
    "# response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\HuggingFaceCache\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\transformers\\generation\\utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Wie alte sind Sie?</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = './llm_model'\n",
    "os.environ['TRANSFORMERS_CACHE'] = './llm_model'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "# input_text = \"translate English to German: How old are you?\"\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> a slang term</s>\n"
     ]
    }
   ],
   "source": [
    "# input_text = \"what is Langchain ?\"\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m hf_embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[0;32m      7\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m persist_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 11\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'embedding'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "persist_directory = './chroma_db'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding=hf_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects_working\\Audio_transcript\\newEnvAudio\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectordb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferWindowMemory(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create ConversationalRetrievalChain\u001b[39;00m\n\u001b[0;32m     16\u001b[0m conversational_retrieval_chain \u001b[38;5;241m=\u001b[39m ConversationalRetrievalChain\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[0;32m     17\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m---> 18\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m\u001b[43mvectordb\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[0;32m     19\u001b[0m     memory\u001b[38;5;241m=\u001b[39mmemory\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectordb' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Create a pipeline for the HuggingFace model\n",
    "generation_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Wrap the pipeline in a LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)\n",
    "\n",
    "# Initialize memory for conversational context\n",
    "memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "# Create ConversationalRetrievalChain\n",
    "conversational_retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me something about the latest documents.\"\n",
    "response = conversational_retrieval_chain({\"input\": query})\n",
    "\n",
    "print(\"Response:\", response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
